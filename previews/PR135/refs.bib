@article{ABL,
  title     = {The augmented Black--Litterman model: A ranking-free approach to factor-based portfolio construction and beyond},
  author    = {Cheung, Wing},
  journal   = {Quantitative Finance},
  volume    = {13},
  number    = {2},
  pages     = {301--316},
  year      = {2013},
  publisher = {Taylor \& Francis}
}

@article{BBL,
  title    = {On the Bayesian interpretation of Black–Litterman},
  journal  = {European Journal of Operational Research},
  volume   = {258},
  number   = {2},
  pages    = {564-572},
  year     = {2017},
  issn     = {0377-2217},
  doi      = {https://doi.org/10.1016/j.ejor.2016.10.027},
  url      = {https://www.sciencedirect.com/science/article/pii/S037722171630861X},
  author   = {Petter Kolm and Gordon Ritter},
  keywords = {Finance, Investment analysis, Bayesian statistics, Black–Litterman, Portfolio optimization},
  abstract = {We present the most general model of the type considered by Black and Litterman (1991) after fully clarifying the duality between Black–Litterman optimization and Bayesian regression. Our generalization is itself a special case of a Bayesian network or graphical model. As an example, we work out in full detail the treatment of views on factor risk premia in the context of APT. We also consider a more speculative example in which the portfolio manager specifies a view on realized volatility by trading a variance swap.}
}


@article{BDVariance,
  title   = {Portfolio Optimization of Brownian Distance Variance},
  author  = {Cajas, Dany},
  journal = {Available at SSRN},
  year    = {2023}
}

@article{BL,
  title   = {The Black-Litterman model in detail},
  author  = {Walters, CFA and others},
  journal = {Available at SSRN 1314585},
  year    = {2014}
}

@article{BL1,
  title     = {Global portfolio optimization},
  author    = {Black, Fischer and Litterman, Robert},
  journal   = {Financial analysts journal},
  volume    = {48},
  number    = {5},
  pages     = {28--43},
  year      = {1992},
  publisher = {Taylor \& Francis}
}

@article{BOP,
  title    = {Optimal shrinkage estimator for high-dimensional mean vector},
  journal  = {Journal of Multivariate Analysis},
  volume   = {170},
  pages    = {63-79},
  year     = {2019},
  note     = {Special Issue on Functional Data Analysis and Related Topics},
  issn     = {0047-259X},
  doi      = {https://doi.org/10.1016/j.jmva.2018.07.004},
  url      = {https://www.sciencedirect.com/science/article/pii/S0047259X17306036},
  author   = {Taras Bodnar and Ostap Okhrin and Nestor Parolya},
  keywords = {Large-dimensional asymptotics, Mean vector estimation, Random matrix theory, Shrinkage estimator},
  abstract = {In this paper we derive the optimal linear shrinkage estimator for the high-dimensional mean vector using random matrix theory. The results are obtained under the assumption that both the dimension p and the sample size n tend to infinity in such a way that p∕n→c∈(0,∞). Under weak conditions imposed on the underlying data generating mechanism, we find the asymptotic equivalents to the optimal shrinkage intensities and estimate them consistently. The proposed nonparametric estimator for the high-dimensional mean vector has a simple structure and is proven to minimize asymptotically, with probability 1, the quadratic loss when c∈(0,1). When c∈(1,∞) we modify the estimator by using a feasible estimator for the precision covariance matrix. To this end, an exhaustive simulation study and an application to real data are provided where the proposed estimator is compared with known benchmarks from the literature. It turns out that the existing estimators of the mean vector, including the new proposal, converge to the sample mean vector when the true mean vector has an unbounded Euclidean norm.}
}

@article{bruder2012managing,
  title   = {Managing risk exposures using the risk budgeting approach},
  author  = {Bruder, Benjamin and Roncalli, Thierry},
  journal = {Available at SSRN 2009778},
  year    = {2012}
}


@article{BS,
  issn      = {00221090, 17566916},
  url       = {http://www.jstor.org/stable/2331042},
  abstract  = {In portfolio analysis, uncertainty about parameter values leads to suboptimal portfolio choices. The resulting loss in the investor's utility is a function of the particular estimator chosen for expected returns. So, this is a problem of simultaneous estimation of normal means under a well-specified loss function. In this situation, as Stein has shown, the classical sample mean is inadmissible. This paper presents a simple empirical Bayes estimator that should outperform the sample mean in the context of a portfolio. Simulation analysis shows that these Bayes-Stein estimators provide significant gains in portfolio selection problems.},
  author    = {Philippe Jorion},
  journal   = {The Journal of Financial and Quantitative Analysis},
  number    = {3},
  pages     = {279--292},
  publisher = {Cambridge University Press},
  title     = {Bayes-Stein Estimation for Portfolio Analysis},
  urldate   = {2024-03-01},
  volume    = {21},
  year      = {1986}
}

@article{CVaR,
  title     = {Optimization of conditional value-at-risk},
  author    = {Rockafellar, R Tyrrell and Uryasev, Stanislav and others},
  journal   = {Journal of risk},
  volume    = {2},
  pages     = {21--42},
  year      = {2000},
  publisher = {Citeseer}
}

@article{DBHTs,
  title     = {Hierarchical information clustering by means of topologically embedded graphs},
  author    = {Song, Won-Min and Di Matteo, Tiziana and Aste, Tomaso},
  journal   = {PloS one},
  volume    = {7},
  number    = {3},
  pages     = {e31929},
  year      = {2012},
  publisher = {Public Library of Science San Francisco, USA}
}

@incollection{DDs,
  author    = {A. Chekhlov and S. Uryasev and M. Zabarankin},
  editor    = {Panos M Pardalos and Athanasios Migdalas and George Baourakis},
  title     = {{Portfolio Optimization With Drawdown Constraints}},
  booktitle = {{Supply Chain And Finance}},
  publisher = {World Scientific Publishing Co. Pte. Ltd.},
  year      = 2004,
  month     = {Juni},
  volume    = {},
  number    = {},
  series    = {World Scientific Book Chapters},
  edition   = {},
  chapter   = {13},
  pages     = {209-228},
  doi       = {},
  keywords  = {Finance; Supply Chain; E-Commerce; Optimization; Mathematical Modeling; Operations Research},
  abstract  = {We propose a new one-parameter family of risk measures, which is called Conditional Draw-down-at-Risk (CDaR). These measures of risk are functionals of the portfolio drawdown (underwater) curve considered in an active portfolio management. For some value of the tolerance parameter β, the CDaR is defined as the mean of the worst (1 - β) * 100\% drawdowns. The CDaR risk measure includes the Maximal Drawdown and Average Drawdown as its limiting cases. For a particular example, we find the optimal portfolios for a case of Maximal Drawdown, a case of Average Drawdown, and several intermediate cases between these two. The CDaR family of risk measures is similar to Conditional Value-at-Risk (CVaR), which is also called Mean Shortfall, Mean Access loss, or Tail Value-at-Risk. Some recommendations on how to select the optimal risk measure for getting practically stable portfolios are provided. We solved a real life portfolio allocation problem using the proposed measures.},
  url       = {https://ideas.repec.org/h/wsi/wschap/9789812562586_0013.html}
}

@article{EVaR,
  title    = {Portfolio optimization with entropic value-at-risk},
  journal  = {European Journal of Operational Research},
  volume   = {279},
  number   = {1},
  pages    = {225-241},
  year     = {2019},
  issn     = {0377-2217},
  doi      = {https://doi.org/10.1016/j.ejor.2019.02.007},
  url      = {https://www.sciencedirect.com/science/article/pii/S0377221719301183},
  author   = {Amir Ahmadi-Javid and Malihe Fallah-Tafti},
  keywords = {Risk analysis, Portfolio optimization, Coherent risk measures, Stochastic programming, Large-scale convex optimization},
  abstract = {The entropic value-at-risk (EVaR) is a new coherent risk measure, which is an upper bound for both the value-at-risk (VaR) and conditional value-at-risk (CVaR). One of the important properties of the EVaR is that it is strongly monotone over its domain and strictly monotone over a broad sub-domain including all continuous distributions, whereas well-known monotone risk measures such as the VaR and CVaR lack this property. A key feature of a risk measure, besides its financial properties, is its applicability in large-scale sample-based portfolio optimization. If the negative return of an investment portfolio is a differentiable convex function for any sampling observation, the portfolio optimization with the EVaR results in a differentiable convex program whose number of variables and constraints is independent of the sample size, which is not the case for the VaR and CVaR even if the portfolio rate linearly depends on the decision variables. This enables us to design an efficient algorithm using differentiable convex optimization. Our extensive numerical study indicates the high efficiency of the algorithm in large scales, when compared with the existing convex optimization software packages. The computational efficiency of the EVaR and CVaR approaches are generally similar, but the EVaR approach outperforms the other as the sample size increases. Moreover, the comparison of the portfolios obtained for a real case by the EVaR and CVaR approaches shows that the EVaR-based portfolios can have better best, mean, and worst return rates as well as Sharpe ratios.}
}

@article{EVaR1,
  title     = {Entropic value-at-risk: A new coherent risk measure},
  author    = {Ahmadi-Javid, Amir},
  journal   = {Journal of Optimization Theory and Applications},
  volume    = {155},
  pages     = {1105--1123},
  year      = {2012},
  publisher = {Springer}
}



@article{EVaR3,
  title   = {Entropic portfolio optimization: a disciplined convex programming framework},
  author  = {Cajas, Dany},
  journal = {Available at SSRN 3792520},
  year    = {2021}
}

@article{FM,
  title     = {High dimensional covariance matrix estimation using a factor model},
  author    = {Fan, Jianqing and Fan, Yingying and Lv, Jinchi},
  journal   = {Journal of Econometrics},
  volume    = {147},
  number    = {1},
  pages     = {186--197},
  year      = {2008},
  publisher = {Elsevier}
}

@incollection{FM1,
  title     = {The arbitrage theory of capital asset pricing},
  author    = {Ross, Stephen A},
  booktitle = {Handbook of the fundamentals of financial decision making: Part I},
  pages     = {11--30},
  year      = {2013},
  publisher = {World Scientific}
}

@article{Gerber,
  title     = {The Gerber statistic: A robust co-movement measure for portfolio optimization},
  author    = {Gerber, Sander and Markowitz, Harry M and Ernst, Philip A and Miao, Yinsen and Javid, Babak and Sargen, Paul},
  journal   = {The Journal of Portfolio Management},
  volume    = {48},
  number    = {3},
  pages     = {87--102},
  year      = {2022},
  publisher = {Institutional Investor Journals Umbrella}
}


@article{GMD,
  title     = {Stochastic dominance, mean variance, and Gini's mean difference},
  author    = {Yitzhaki, Shlomo},
  journal   = {The American Economic Review},
  volume    = {72},
  number    = {1},
  pages     = {178--185},
  year      = {1982},
  publisher = {JSTOR}
}

@article{HERC,
  title   = {The hierarchical equal risk contribution portfolio},
  author  = {Raffinot, Thomas},
  journal = {Available at SSRN 3237540},
  year    = {2018}
}

@article{HERC1,
  title     = {Hierarchical clustering-based asset allocation},
  author    = {Raffinot, Thomas},
  journal   = {The Journal of Portfolio Management},
  volume    = {44},
  number    = {2},
  pages     = {89--99},
  year      = {2017},
  publisher = {Institutional Investor Journals Umbrella}
}

@article{HGR,
  title    = {Low bias histogram-based estimation of mutual information for feature selection},
  journal  = {Pattern Recognition Letters},
  volume   = {33},
  number   = {10},
  pages    = {1302-1308},
  year     = {2012},
  issn     = {0167-8655},
  doi      = {https://doi.org/10.1016/j.patrec.2012.02.022},
  url      = {https://www.sciencedirect.com/science/article/pii/S0167865512000761},
  author   = {Abdenour Hacine-Gharbi and Philippe Ravier and Rachid Harba and Tayeb Mohamadi},
  keywords = {Mutual information, Feature selection, Bias, Dimensionality reduction, Shannon entropy, Speech recognition},
  abstract = {This paper presents a low bias histogram-based estimation of mutual information and its application to feature selection problems. By canceling the first order bias, the estimation avoids the bias accumulation problem that affects classical methods. As a consequence, on a synthetic feature selection problem, only the proposed method results in the exact number of features to be chosen in the Gaussian case when compared to four other approaches. In a speech recognition application, the proposed method and the Sturges method are the only ones that lead to a correct number of selected features in the noise free case. In the reduced data case, only the proposed method points out the optimal number of features to select. Finally, in the noisy case, only the proposed method leads to results of high quality; other methods show severely underestimated numbers of selected features.}
}

@phdthesis{HRP,
  title  = {Exploration of Hierarchical Clustering in Long-Only Risk-Based Portfolio Optimization},
  author = {Sj{\"o}strand, Daniel and Behnejad, Nima and Richter, Martin},
  year   = {2020},
  school = {Master thesis, CBS, Copenhagen}
}
@article{HRP1,
  title     = {Building diversified portfolios that outperform out of sample},
  author    = {De Prado, Marcos Lopez},
  journal   = {The Journal of Portfolio Management},
  volume    = {42},
  number    = {4},
  pages     = {59--69},
  year      = {2016},
  publisher = {Institutional Investor Journals Umbrella}
}

@article{HRP3,
  title   = {A constrained hierarchical risk parity algorithm with cluster-based capital allocation},
  author  = {Pfitzinger, Johann and Katzke, Nico and others},
  journal = {Stellenbosch University, Department of Economics},
  year    = {2019}
}


@article{J_LoGo,
  title     = {Parsimonious modeling with information filtering networks},
  author    = {Barfuss, Wolfram and Massara, Guido Previde and Di Matteo, T. and Aste, Tomaso},
  journal   = {Phys. Rev. E},
  volume    = {94},
  issue     = {6},
  pages     = {062306},
  numpages  = {12},
  year      = {2016},
  month     = {Dec},
  publisher = {American Physical Society},
  doi       = {10.1103/PhysRevE.94.062306},
  url       = {https://link.aps.org/doi/10.1103/PhysRevE.94.062306}
}

@book{JS1,
  title     = {Risk and asset allocation},
  author    = {Meucci, Attilio},
  volume    = {1},
  year      = {2005},
  publisher = {Springer}
}

@article{JS2,
  url     = {http://dx.doi.org/10.1561/2000000072},
  year    = {2016},
  volume  = {9},
  journal = {Foundations and Trends® in Signal Processing},
  title   = {A Signal Processing Perspective on Financial Engineering},
  doi     = {10.1561/2000000072},
  issn    = {1932-8346},
  number  = {1–2},
  pages   = {1-231},
  author  = {Yiyong Feng and Daniel P. Palomar}
}


@incollection{Kelly1,
  title     = {Chaper 9 - The kelly criterion in blackjack sports betting, and the stock market*},
  editor    = {S.A. Zenios and W.T. Ziemba},
  booktitle = {Handbook of Asset and Liability Management},
  publisher = {North-Holland},
  address   = {San Diego},
  pages     = {385-428},
  year      = {2008},
  isbn      = {978-0-444-53248-0},
  doi       = {https://doi.org/10.1016/B978-044453248-0.50015-0},
  url       = {https://www.sciencedirect.com/science/article/pii/B9780444532480500150},
  author    = {Edward O. Thorp},
  abstract  = {Publisher Summary
               The central problem for gamblers is to find positive expectation bets. But the gambler also needs to know how to manage his money, i.e., how much to bet. In the stock market (more inclusively, the securities markets), the problem is similar but more complex. The gambler, who is now an “investor”, looks for “excess risk adjusted return”. In both these settings, this chapter explores the use of the Kelly criterion, which is to maximize the expected value of the logarithm of wealth (“maximize expected logarithmic utility”). The criterion is known to economists and financial theorists by names such as the ”geometric mean maximizing portfolio strategy”, maximizing logarithmic utility, the growth-optimal strategy, and the capital growth criterion. It initiates the practical application of the Kelly criterion by using it for card counting in blackjack. It presents some useful formulas and methods to answer various natural questions about it that arise in blackjack and other gambling games. It illustrates its recent use in a successful casino sports betting system. It discusses its application to the securities markets where it has helped the author to make a 30-year total of 80 billion dollars worth of “bets”.}
}

@article{Kelly2,
  title   = {Kelly portfolio optimization: a disciplined convex programming framework},
  author  = {Cajas, Dany},
  journal = {Available at SSRN 3833617},
  year    = {2021}
} 

@article{KT1,
  title   = {Convex Optimization of Portfolio Kurtosis},
  author  = {Cajas, Dany},
  journal = {Available at SSRN},
  year    = {2022}
}

@article{KT2,
  title   = {Approximation of Portfolio Kurtosis through Sum of Squared Quadratic Forms},
  author  = {Cajas, Dany},
  journal = {Available at SSRN 4472793},
  year    = {2023}
}

@inbook{LPM,
  author    = {Mansini, Renata
               and Ogryczak, W{\l}odzimierz
               and Speranza, M. Grazia},
  title     = {Linear Models for Portfolio Optimization},
  booktitle = {Linear and Mixed Integer Programming for Portfolio Optimization},
  year      = {2015},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {19--45},
  abstract  = {Nowadays, Quadratic Programming (QP) models, like Markowitz model, are not hard to solve, thanks to technological and algorithmic progress. Nevertheless, Linear Programming (LP) models remain much more attractive from a computational point of view for several reasons. In order to guarantee that a portfolio takes advantage from diversification, no risk or safety measures can be a linear function of the weights of the assets. Is it possible to have linear models for portfolio optimization? How can we measure the risk or safety in order to have a linear model? In this chapter, we show how it is possible to achieve a linear form of the overall optimization problem for several different risk measures through the concept of scenarios for the rates of return. The variance is the classical statistical quantity used to measure the dispersion of a random variable from its mean. However, there are several other ways to measure dispersion. We introduce the mean absolute deviation (MAD), the Gini's mean difference (GMD) as basic LP computable risk measures and the worst realization (Minimax) and the Conditional Value-at-Risk (CVaR) as basic LP computable safety measures. We show how from each risk measure it is possible to build its safety measure and vice versa. Ratio measures and further enhanced risk measures and shortfall risk measures based on the concept of risk as failure to achieve a defined target are also discussed.},
  isbn      = {978-3-319-18482-1},
  doi       = {10.1007/978-3-319-18482-1_2},
  url       = {https://doi.org/10.1007/978-3-319-18482-1_2}
}

@article{MAD,
  title    = {Mean-Absolute Deviation Portfolio Optimization Model and Its Applications to Tokyo Stock Market},
  author   = {Konno, Hiroshi and Yamazaki, Hiroaki},
  year     = {1991},
  journal  = {Management Science},
  volume   = {37},
  number   = {5},
  pages    = {519-531},
  abstract = {The purpose of this paper is to demonstrate that a portfolio optimization model using the L 1 risk (mean absolute deviation risk) function can remove most of the difficulties associated with the classical Markowitz's model while maintaining its advantages over equilibrium models. In particular, the L 1 risk model leads to a linear program instead of a quadratic program, so that a large-scale optimization problem consisting of more than 1,000 stocks may be solved on a real time basis. Numerical experiments using the historical data of NIKKEI 225 stocks show that the L 1 risk model generates a portfolio quite similar to that of the Markowitz's model within a fraction of time required to solve the latter.},
  keywords = {portfolio optimization; L1 risk function; linear programming; Markowitz's model; single-factor model},
  url      = {https://EconPapers.repec.org/RePEc:inm:ormnsc:v:37:y:1991:i:5:p:519-531}
}

@incollection{MIP1,
  title     = {Reformulation-linearization method for global optimization of mixed integer linear fractional programming problems with application on sustainable batch scheduling},
  author    = {Yue, Dajun and You, Fengqi},
  booktitle = {Computer Aided Chemical Engineering},
  volume    = {33},
  pages     = {949--954},
  year      = {2014},
  publisher = {Elsevier}
}

@book{MLAM,
  place      = {Cambridge},
  series     = {Elements in Quantitative Finance},
  title      = {Machine Learning for Asset Managers},
  publisher  = {Cambridge University Press},
  author     = {López de Prado, Marcos M.},
  year       = {2020},
  collection = {Elements in Quantitative Finance}
}

@article{NCO,
  title   = {A robust estimator of the efficient frontier},
  author  = {Lopez de Prado, Marcos},
  journal = {Available at SSRN 3469961},
  year    = {2016}
}

@article{NHPG,
  title    = {Nested hierarchies in planar graphs},
  journal  = {Discrete Applied Mathematics},
  volume   = {159},
  number   = {17},
  pages    = {2135-2146},
  year     = {2011},
  issn     = {0166-218X},
  doi      = {https://doi.org/10.1016/j.dam.2011.07.018},
  url      = {https://www.sciencedirect.com/science/article/pii/S0166218X11002794},
  author   = {Won-Min Song and T. Di Matteo and Tomaso Aste},
  keywords = {Maximal planar graph, 3-clique, Bubble, Hierarchy, Community},
  abstract = {We construct a partial order relation which acts on the set of 3-cliques of a maximal planar graph G and defines a unique hierarchy. We demonstrate that G is the union of a set of special subgraphs, named 'bubbles', that are themselves maximal planar graphs. The graph G is retrieved by connecting these bubbles in a tree structure where neighboring bubbles are joined together by a 3-clique. Bubbles naturally provide the subdivision of G into communities and the tree structure defines the hierarchical relations between these communities.}
}









@article{NWK1,
  title   = {A Graph Theory Approach to Portfolio Optimization},
  author  = {Cajas, Dany},
  journal = {Available at SSRN},
  year    = {2023}
}

@article{NWK2,
  title   = {A Graph Theory Approach to Portfolio Optimization Part II},
  author  = {Cajas, Dany},
  journal = {Available at SSRN 4667426},
  year    = {2023}
}

@article{OWA,
  title   = {OWA Portfolio Optimization: A Disciplined Convex Programming Framework},
  author  = {Cajas, Dany},
  journal = {Available at SSRN 3988927},
  year    = {2021}
}

@article{OWAA,
  title   = {Efficient Gini Mean Difference and Tail Gini Portfolio Optimization based on P-Norms},
  author  = {Cajas, Dany},
  journal = {Available at SSRN 4711326},
  year    = {2024}
}

@article{OWAL,
  title   = {Higher Order Moment Portfolio Optimization with L-Moments},
  author  = {Cajas, Dany},
  journal = {Available at SSRN 4393155},
  year    = {2023}
}


@article{PMFG,
  author   = {Massara, Guido Previde and Di Matteo, T. and Aste, Tomaso},
  title    = {{Network Filtering for Big Data: Triangulated Maximally Filtered Graph}},
  journal  = {Journal of Complex Networks},
  volume   = {5},
  number   = {2},
  pages    = {161-178},
  year     = {2016},
  month    = {06},
  abstract = {{We propose a network-filtering method, the Triangulated Maximally Filtered Graph (TMFG), that provides an approximate solution to the Weighted Maximal Planar Graph problem. The underlying idea of TMFG consists in building a triangulation that maximizes a score function associated with the amount of information retained by the network. TMFG uses as weights any arbitrary similarity measure to arrange data into a meaningful network structure that can be used for clustering, community detection and modelling. The method is fast, adaptable and scalable to very large datasets; it allows online updating and learning as new data can be inserted and deleted with combinations of local and non-local moves. Further, TMFG permits readjustments of the network in consequence of changes in the strength of the similarity measure. The method is based on local topological moves and can therefore take advantage of parallel and GPUs computing. We discuss how this network-filtering method can be used intuitively and efficiently for big data studies and its significance from an information-theoretic perspective.}},
  issn     = {2051-1310},
  doi      = {10.1093/comnet/cnw015},
  url      = {https://doi.org/10.1093/comnet/cnw015},
  eprint   = {https://academic.oup.com/comnet/article-pdf/5/2/161/13794756/cnw015.pdf}
}

@article{RB,
  title   = {Constrained risk budgeting portfolios: Theory, algorithms, applications \& puzzles},
  author  = {Richard, Jean-Charles and Roncalli, Thierry},
  journal = {arXiv preprint arXiv:1902.05710},
  year    = {2019}
}


@article{RB1,
  title   = {Managing risk exposures using the risk budgeting approach},
  author  = {Bruder, Benjamin and Roncalli, Thierry},
  journal = {Available at SSRN 2009778},
  year    = {2012}
}

@article{RLVaR,
  title   = {Portfolio Optimization of Relativistic Value at Risk},
  author  = {Cajas, Dany},
  journal = {Available at SSRN 4378498},
  year    = {2023}
}


@article{RRB1,
  title     = {Risk return trade-off in relaxed risk parity portfolio optimization},
  author    = {Gambeta, Vaughn and Kwon, Roy},
  journal   = {Journal of risk and financial management},
  volume    = {13},
  number    = {10},
  pages     = {237},
  year      = {2020},
  publisher = {MDPI}
}

@article{SB,
  title    = {An enhanced Gerber statistic for portfolio optimization},
  journal  = {Finance Research Letters},
  volume   = {49},
  pages    = {103229},
  year     = {2022},
  issn     = {1544-6123},
  doi      = {https://doi.org/10.1016/j.frl.2022.103229},
  url      = {https://www.sciencedirect.com/science/article/pii/S1544612322004317},
  author   = {William Smyth and Daniel Broby},
  keywords = {Estimation error, Gerber statistic, Portfolio optimization, Shrinkage, Equity co-movements, Modern portfolio theory},
  abstract = {The purpose of this letter is to introduce a modified version of the Gerber statistic resulting in the enhancement of its function as a measure of statistical co-movement. The modification centres around the redefinition of zones and thresholds, alongside the use of finite real-valued contributions rather than discrete binary counts in assigning value to individual co-movements. Arguments for the former are based on the statistical alignment of data series for the purposes of more effectively delineating concordant and discordant co-movement. Arguments for the latter are based on attributing greater weight to better information. Collectively this approach simultaneously incorporates the merits of Gerber-like thresholds and zoning, and conventional correlation-like co-movement measurement.}
}

@article{SD,
  issn      = {00221082, 15406261},
  url       = {http://www.jstor.org/stable/2975974},
  author    = {Harry Markowitz},
  journal   = {The Journal of Finance},
  number    = {1},
  pages     = {77--91},
  publisher = {[American Finance Association, Wiley]},
  title     = {Portfolio Selection},
  urldate   = {2024-03-03},
  volume    = {7},
  year      = {1952}
}
@article{Skew,
  title   = {On the Spectral Decomposition of Portfolio Skewness and its Application to Portfolio Optimization},
  author  = {Cajas, Dany},
  journal = {Available at SSRN 4540021},
  year    = {2023}
}

@article{SSD,
  title    = {Twenty years of linear programming based portfolio optimization},
  journal  = {European Journal of Operational Research},
  volume   = {234},
  number   = {2},
  pages    = {518-535},
  year     = {2014},
  note     = {60 years following Harry Markowitz’s contribution to portfolio theory and operations research},
  issn     = {0377-2217},
  doi      = {https://doi.org/10.1016/j.ejor.2013.08.035},
  url      = {https://www.sciencedirect.com/science/article/pii/S0377221713007194},
  author   = {Renata Mansini and Wlodzimierz Ogryczak and M. Grazia Speranza},
  keywords = {Survey, LP computable mean-risk and mean-safety models, Real features, Transaction costs, Exact and heuristic algorithms},
  abstract = {Markowitz formulated the portfolio optimization problem through two criteria: the expected return and the risk, as a measure of the variability of the return. The classical Markowitz model uses the variance as the risk measure and is a quadratic programming problem. Many attempts have been made to linearize the portfolio optimization problem. Several different risk measures have been proposed which are computationally attractive as (for discrete random variables) they give rise to linear programming (LP) problems. About twenty years ago, the mean absolute deviation (MAD) model drew a lot of attention resulting in much research and speeding up development of other LP models. Further, the LP models based on the conditional value at risk (CVaR) have a great impact on new developments in portfolio optimization during the first decade of the 21st century. The LP solvability may become relevant for real-life decisions when portfolios have to meet side constraints and take into account transaction costs or when large size instances have to be solved. In this paper we review the variety of LP solvable portfolio optimization models presented in the literature, the real features that have been modeled and the solution approaches to the resulting models, in most of the cases mixed integer linear programming (MILP) models. We also discuss the impact of the inclusion of the real features.}
}

@article{TG,
  title     = {Dual stochastic dominance and quantile risk measures},
  author    = {Ogryczak, Wlodzimierz and Ruszczy{\'n}ski, Andrzej},
  journal   = {International Transactions in Operational Research},
  volume    = {9},
  number    = {5},
  pages     = {661--680},
  year      = {2002},
  publisher = {Wiley Online Library}
}

@article{UCI,
  title   = {The investor's guide to fidelity funds},
  author  = {Martin, Peter G and McCann, Byron B},
  journal = {(No Title)},
  year    = {1989}
}

@article{WC,
  title   = {Robust Asset Allocation},
  author  = {Reha H. T{\"u}t{\"u}nc{\"u} and Matthias Koenig},
  journal = {Annals of Operations Research},
  year    = {2004},
  volume  = {132},
  pages   = {157-187},
  url     = {https://api.semanticscholar.org/CorpusID:2669348}
}

@book{WC1,
  title     = {Uncertainty Set Sizes, Sensitivity Analysis, in Robust Portfolio Optimization},
  author    = {Yang, Mingyu},
  publisher = {University of Waterloo},
  year      = {2019}
}

@book{WC3,
  title     = {Robust portfolio optimization and management},
  author    = {Fabozzi, Frank J and Kolm, Petter N and Pachamanova, Dessislava A and Focardi, Sergio M},
  year      = {2007},
  publisher = {John Wiley \& Sons}
}

@article{WC4,
  title     = {Worst-case value-at-risk and robust portfolio optimization: A conic programming approach},
  author    = {Ghaoui, Laurent El and Oks, Maksim and Oustry, Francois},
  journal   = {Operations research},
  volume    = {51},
  number    = {4},
  pages     = {543--556},
  year      = {2003},
  publisher = {INFORMS}
}

@article{WC5,
  title   = {The worst-case risk of a portfolio},
  author  = {Lobo, Miguel Sousa and Boyd, Stephen},
  journal = {Unpublished manuscript. Available from http://faculty. fuqua. duke. edu/\% 7Emlobo/bio/researchfiles/rsk-bnd. pdf},
  year    = {2000}
}

@misc{WC6,
  url     = {https://palomar.home.ece.ust.hk/ELEC5470_lectures/slides_robust_optim.pdf},
  journal = {Robust optimization with applications},
  author  = {Palomar, Daniel P.},
  year    = {2020},
  month   = {Sep}
}


@article{WR,
  title     = {On LP solvable models for portfolio selection},
  author    = {Mansini, Renata and Ogryczak, W{\l}odzimierz and Speranza, M Grazia},
  journal   = {Informatica},
  volume    = {14},
  number    = {1},
  pages     = {37--62},
  year      = {2003},
  publisher = {Institute of Mathematics and Informatics}
}
